WORKFLOW
- user runs xweb first with '--init' flag
 > it traverses all HTML files recursively, identifying HTML section, header and footer elements ('sections')
 > it reflows all HTML
 > builds a list of sections
 > sections which are identical are updated with the same id
 > sections which are different are given a unique id
 > a list of sections ids is shown across all files
 > a data-hash attrbute is added to each

- user updates sections in HTML and runs 'xweb' to update all sections
 > it traverses all HTML files recursively, identifying HTML section elements
 > HTML sections are compared against data-hash attribute
 > if more than one updated per id, it asks which one is master
 > all mismatching sections are updated and files written back

IMPLEMENTATION
- per-file struct has:
 > file pointer
 > html tree
 > updated flag

- per-section struct has:
 > id
 > highest revision
 > list of html nodes to replace
 > pointer to per-file struct to set writeback flag

- for each html file found via filepath.Walk:
 > use golang.org/x/net/html [updating via file, err := os.OpenFile("sample.html", os.O_RDWR | os.O_TRUNC, 0644); html.Render(file, doc)]
 > create per-file datastructure
 > for each "section" element, stored by id
   > if a "data-xdeb" attribute present, store revision if higher
   > if multiple highest revisions, error out

- for each per-section struct:
 > if highest revision is 0, skip
 > iterate HTML node list, performing deep copy, preseving attributes eg class
 > set linked per-file writeback flag

- for each file struct:
 > if writeback set, rerender to file

TODO
- initial setup mode
 > parse all files, looking for section HTML element
   - remove id attribute
   - perform deep hash
   - store in map by hash, including id
